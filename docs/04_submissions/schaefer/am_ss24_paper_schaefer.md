---
layout: default
title: Session
nav_exclude: true
---

# Research Document - Adam Streicher

### Topic: Connecting Audio with Video real-time generation, towards universal concepts of parameter mappings in audiovisual live instruments

Description / Background:





* What specifically interests you within that topic? 

    I'm generally interested in the field of building instrument-like software. Furthermore I'm interested in the field of audiovisual live performances or installations. A big emphasis, for me, is here on the term "audiovisual". I remember seeing works like Ryoji Ikedas "Datamatics", which isn't necessarily a Live performance but most-likely a real-time generated work.(he uses PureData) Beyond the aesthetics i personally really like, what was outstanding for me is the impression that sound and visuals are so coherently aligned. It almost felt it's one thing. I'm very much interested in this phenomena of the perceived "oneness" of audio & visual content. Obviously this effect is a very ordinary thing in the perception of the real world. If we perceive an event, that stimulates the brain with auditive & visual signals its not of a big surprise that they first appear as unified experience resulting from that one event. Despite our ability to discriminate between the multiple perceptory stimuli and assign them properly to the regarding domain of perception. I remember making some rersearch for my BA Thesis on the topic of multi-sensory neurons & integration and how important those concepts are considered for how our brains work. There are multi-semnsory neurons and cells that, if I understood i correctly connect stimuli of different modalities even before any centralized processing of percoptory stimulation. There was a paper that made research on this in newborn cats, which motoric abilities are in a very young age quite underdevolped, they behave really clumsy in the first days or weeks. At a certain point in their earliest development their motoric abilities drastically improve at very high pace. The paper argued that in this phase of development the brain region, considered to be rsponsible for multi-sensory integration, the "Superior Colliculus" is extremly active. (poorly recalled by me, this is the actual paper: https://www.jneurosci.org/content/jneuro/17/7/2429.full.pdf)

    So my point is, multi-sensory integration and therefore multimodal perception is by far not a special thing to audiovisual forms of art. However, when creating such form of art or media, the creators face the challenges of properly / coherently creating & compositing audio and visual contents to deliver a believable, "fitting" arrangement of both. With the aim that the viewer has a unified experience that isn't distracted by the perception of distinct contents of the different modal domains. But the creator absolutely works in distinct areas. Technically its absolutely distinct in the workprocess. (eg. Sound & Camera Department in Film, the Department of Montage is then the area who conncets it again i guess). Im claiming the combination of those is usually a big matter of psychoacoustics or psychological studying of the subjective effect on the way its combined. My interest in what i call "audiovisual instrument" is partly to try to combine those domains, technically or algorithmicly  already at the stage of synthesis or generation. So in some way getting closer to the occurence of audiovisual stimuli in the real world where auditive & visual signals come from the same source or event. My interest is therefore exploring at what stage signals that trigger Audio Or Video in digital media creation tools could be aligned or combined and if this makes effects on how human subjects might perceive those contents as closer to "feeling like one" in the sense of a higher activity in multi-sensory integretated stimulation. 


* What further characteristics does the topic have? 

* What questions could you ask about that topic? 

Q1: Focussed on multimodal user experience, which parameters of such instruments seem “fitting” to each other ?

Q2: Are there multimodal patterns or direct connections of parameters in the creation of audiovisual instruments & the respective user interfaces, that significantly strengthen the intersubjective impression of a naturally, unified experience of playing rather then an experience of playing an instruemnt that artificially combined two modal domains?

* How could you solve those questions? 

 For example, turning up the amount of a reverb effect on an audio track might add more “space” or “width” in the perception of the sound, how could this subjective experience of the concept of width or space apply to a visual parameter ? To which parameter in the visual domain would this concept apply the “best” / most coherent ? As an example, a 2D image with a simple circle, the concept of a increasing amount of width / depth / space might be translated to a visual effect that blurs out hard edges of the circle or creates a increasing repetition of that circle in the background (layered behind) that has a smooth fall off in opacity so that it looks like the circle is decaying into the background, which might be a subjectively adequate analogy to the perception of the described effect in the auditive domain.

For a research on this, obviously multiple of such practical scenarios have to be prepared. There would need to be different ones in terms of audiovisual content (maybe one with a circle and a certain sound, maybe another one with a rectangle and a different sound). But, moreover there also needs to be different sets of parameter mappings for each scenarios (so eg. one, like described, where the reverb effect is bound / mapped to such a visual effect, but also another ones, where for example the reverb parameter is mapped to a different visual effect).

The idea then is to evaluate (trying to objectify / get a statemnt thats is intersubjectively evaluated) what is perceived as fitting well, by letting multiple subjects from different areas test it.

For that, I would prepare a questionnaire, with questions like “which playful encounter with those prepared “instruments” felt most natural to you? "natural", in the sense did it felt like playing one instrument rather then playing a visual content generation patch combined with a audio content generation patch.

Another question would be why that is or is not the case. So my approach would be to get rather long answers, trying to understand as much as possible each individual experience of the subjects while playing with those instruments. I would want them to not try to make objective statements about the instruments but rather statements that are as subjective as possible, really emphasising on how they / it felt. Maybe the question why they think they felt this or the other way is less important then the actual description of their very raw experience.
____

### Research Question:

Q0: How can intersubjectively coherent parameter mappings in the field of audiovisual instruments be achieved?





____

### Methodology:

* case studies for different sets of parameter combinations
* qualitative interviews
* qualitative phenomenological research design
____

### Sources:


---



Topic II - Artistic Simulation of Living Systems in Installative Media Art. 

Description: The term Aliveness and related Theories (like Panpsychism eg.) in general. Genetic Algorithms and evolutionary Autonomous Agents Systems in specific. Open for other algorithmic approaches as well.

* What questions could you ask about that topic? 

What means "being alive" or Aliveness ? 
Where does it start? 
What makes an entity seem "alive"? 
What are the attributes that define the liveliness of an entity / an organism? 

Q1: How might attributes, connected to the liveliness of an organism be credibly imitated for enhancing the impression of liveliness in non-organic, digital actors / entities?

Q2: How can the concept of Growth & Evolution be algorithmically applied in installative artworks in the field of new media arts, to enhance impressions of a living system?

So Q1 would focus more on the single actor and how lets say some particle could be moved by some simulated forces that make his movement seem more like the movement of an actual organic being.
Q2 would focus more on the whole installation, tring to understand it as some kind of artificial ecosystem and would focus on how to make this system or the whole installation feel somewhat alive.


---